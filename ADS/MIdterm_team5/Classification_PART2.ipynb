{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Package imports\n",
    "%matplotlib inline \n",
    "from IPython.display import Image\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import warnings\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.utils import ConvergenceWarning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "plt.style.use('fivethirtyeight') # Good looking plots\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit, probit, poisson, ols\n",
    "from sklearn import datasets\n",
    "from pybrain.utilities import percentError\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.structure.modules import SoftmaxLayer\n",
    "from pybrain.datasets.classification import ClassificationDataSet\n",
    "from pybrain.tools.validation import Validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creating function for data processing & data cleaning\n",
    "\n",
    "def featureSelectionRFE():\n",
    "    from sklearn.feature_selection import RFE\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression()\n",
    "    # create the RFE model and select 10 attributes\n",
    "    rfe = RFE(model, 10)\n",
    "    rfe = rfe.fit(train_data[0:,1:], train_data[0:,0])\n",
    "    # summarize the selection of the attributes\n",
    "    print(rfe.support_)\n",
    "    print(rfe.ranking_)\n",
    "    print(rfe.n_features_)\n",
    "    #Check the accuracy of the model\n",
    "    rfe.score(train_data[0:,1:], train_data[0:,0])\n",
    "\n",
    "def transformDF(df):\n",
    "    df['delinquent'] = (df.delq_sts > 0).astype(int)\n",
    "    df = df.drop(['cd_zero_bal'],axis = 1)\n",
    "    df = df.drop('delq_sts', axis = 1)\n",
    "    return df\n",
    "\n",
    "def createDummies(df):\n",
    "    dummies = pd.get_dummies(df['repch_flag']).rename(columns=lambda x: 'repch_flag' + str(x))\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    dummies1 = pd.get_dummies(df['cd_zero_bal']).rename(columns=lambda x: 'cd_zero_bal' + str(x))\n",
    "    df = pd.concat([df, dummies1], axis=1)\n",
    "    return df\n",
    "    \n",
    "\n",
    "def fillNA(df):\n",
    "    df['delq_sts'] = df['delq_sts'].fillna(0)\n",
    "    df['repch_flag']=df['repch_flag'].fillna('X')\n",
    "    df['flag_mod']=df['flag_mod'].fillna('N')\n",
    "    df['cd_zero_bal']=df['cd_zero_bal'].fillna(0)\n",
    "    df['dt_zero_bal']=df['dt_zero_bal'].fillna('189901')\n",
    "    df['non_int_brng_upb']=df['non_int_brng_upb'].fillna(0)\n",
    "    df['dt_lst_pi']=df['dt_lst_pi'].fillna('189901')\n",
    "    df['mi_recoveries']=df['mi_recoveries'].fillna(0)\n",
    "    df['net_sale_proceeds']=df['net_sale_proceeds'].fillna(0)\n",
    "    df['non_mi_recoveries']=df['non_mi_recoveries'].fillna(0)\n",
    "    df['expenses']=df['expenses'].fillna(0)\n",
    "    df['legal_costs']=df['legal_costs'].fillna(0)\n",
    "    df['maint_pres_costs']=df['maint_pres_costs'].fillna(0)\n",
    "    df['taxes_ins_costs']=df['taxes_ins_costs'].fillna(0)\n",
    "    df['misc_costs']=df['misc_costs'].fillna(0)\n",
    "    df['actual_loss']=df['actual_loss'].fillna(0)\n",
    "    df['modcost']=df['modcost'].fillna(0)\n",
    "    return df\n",
    "\n",
    "def changedtype(df):\n",
    "    #Change the data types for all column\n",
    "    df[['non_int_brng_upb','actual_loss','modcost','misc_costs','taxes_ins_costs','maint_pres_costs','legal_costs','expenses','current_int_rt','current_upb']] = df[['non_int_brng_upb','actual_loss','modcost','misc_costs','taxes_ins_costs','maint_pres_costs','legal_costs','expenses','current_int_rt','current_upb']].astype('float64')\n",
    "    df[['loan_age','mths_remng','cd_zero_bal','delq_sts','flag_mod_n']] = df[['loan_age','mths_remng','cd_zero_bal','delq_sts','flag_mod_n']].astype('int64')\n",
    "    df[['svcg_cycle','dt_zero_bal','dt_lst_pi']] = df[['svcg_cycle','dt_zero_bal','dt_lst_pi']].astype('str')\n",
    "    return df\n",
    "\n",
    "\n",
    "def createDataFrame(str):\n",
    "    perf_df = pd.read_csv(str ,sep=\"|\", names=['id_loan','svcg_cycle','current_upb','delq_sts','loan_age','mths_remng', 'repch_flag','flag_mod', 'cd_zero_bal', 'dt_zero_bal','current_int_rt','non_int_brng_upb','dt_lst_pi','mi_recoveries', 'net_sale_proceeds','non_mi_recoveries','expenses', 'legal_costs', 'maint_pres_costs','taxes_ins_costs','misc_costs','actual_loss', 'modcost'],skipinitialspace=True,error_bad_lines=False, index_col=False, dtype='unicode') \n",
    "    perf_df['delq_sts'] = [ 999 if x=='R' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "    perf_df['delq_sts'] = [ 0 if x=='XX' else x for x in (perf_df['delq_sts'].apply(lambda x: x))]\n",
    "    perf_df['flag_mod_n'] = [ 0 if x=='N' else 1 for x in (perf_df['flag_mod'].apply(lambda x: x))]\n",
    "    perf_df[['net_sale_proceeds']] = [ 0 if x=='U' else x for x in (perf_df['net_sale_proceeds'].apply(lambda x: x))]\n",
    "    perf_df[['net_sale_proceeds']] = [ perf_df['current_upb'] if x=='C' else x for x in (perf_df['net_sale_proceeds'].apply(lambda x: x))]\n",
    "    perf_df['Year'] = ['19'+x if x=='99' else '20'+x for x in (perf_df['id_loan'].apply(lambda x: x[2:4]))]\n",
    "    perf_df = fillNA(perf_df)\n",
    "    perf_df = changedtype(perf_df)\n",
    "    return perf_df\n",
    "\n",
    "#Ensures all required features \n",
    "def checkAllReqColumns(df):\n",
    "    for x in cols_to_keep:\n",
    "        if not x in df.columns:\n",
    "            df[x]=0.0\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputpath=str(os.getcwd())+\"\\\\\"+'input.csv'\n",
    "\n",
    "reader=csv.reader(open(inputpath),delimiter=',')\n",
    "data=[]\n",
    "for row in reader:\n",
    "    data.append(row)\n",
    "    \n",
    "train=data[0][0]\n",
    "test=data[0][1]\n",
    "\n",
    "#Creating DataFrame\n",
    "foldername= 'historical_data1_'+str(year)\n",
    "Historicalpath=str(os.getcwd())+\"\\\\\"+foldername\n",
    "train=Historicalpath+\"\\historical_data1_time_\"+str(train)+\".txt\"\n",
    "test=Historicalpath+\"\\historical_data1_time_\"+str(test)+\".txt\"\n",
    "print(\"Creating Training Dataframe...\")\n",
    "train_df = createDataFrame(train)\n",
    "print(\"Creating Test Dataframe...\")\n",
    "test_df = createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating Dummy Variables\n",
    "print(\"Creating Dummy vars...\")\n",
    "train_df=createDummies(train_df)\n",
    "test_df=createDummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove the deliquent column for the df\n",
    "print(\"Transforming Dataframes...\")\n",
    "train_df=transformDF(train_df)\n",
    "test_df=transformDF(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get all the column which are either int /Float\n",
    "print(\"Converting to Numeric...\")\n",
    "train_num_df = train_df._get_numeric_data()\n",
    "test_num_df = test_df._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Keep the following 10 features (variables) which are important\n",
    "cols_to_keep = ['cd_zero_bal6', 'cd_zero_bal1', 'repch_flagX','cd_zero_bal0','repch_flagN','repch_flagY','current_int_rt','cd_zero_bal3','flag_mod_n','loan_age']\n",
    "print(\"Checking all required columns in train and test dataframes\")\n",
    "train_num_df=checkAllReqColumns(train_num_df)\n",
    "test_num_df= checkAllReqColumns(test_num_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting the input parameter for Classification Algorithm\n",
    "print(\"Creating X and y variables for Train and Test Dataframes\")\n",
    "train_num_df_X = train_num_df[cols_to_keep]\n",
    "delinquent_train_y = train_num_df['delinquent']\n",
    "\n",
    "test_num_df_X = test_num_df[cols_to_keep]\n",
    "delinquent_test_y = test_num_df['delinquent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train the data using stratified_cross_validation technique\n",
    "def stratified_cv(X, y, clf_class, shuffle=True, n_folds=2, **kwargs):\n",
    "    stratified_k_fold = cross_validation.StratifiedKFold(y, n_folds=n_folds, shuffle=shuffle)\n",
    "    y_pred = y.copy()\n",
    "    for ii, jj in stratified_k_fold:\n",
    "        X_train, X_test = X[ii], X[jj]\n",
    "        y_train = y[ii]\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[jj] = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_data(conf_matrix):\n",
    "    fix, ax = plt.subplots(figsize=(16, 12))\n",
    "    plt.suptitle('Confusion Matrix  on Data Set')\n",
    "    for ii, values in conf_matrix.items():\n",
    "        matrix = values['matrix']\n",
    "        title = values['title']\n",
    "        plt.subplot(2, 2, ii) # starts from 1\n",
    "        plt.title(title);\n",
    "        sns.heatmap(matrix, annot=True,  fmt='');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_logistic_Regression(train_num_df_X, train_y, test_num_df_X, test_y ):\n",
    "    model = LogisticRegression()\n",
    "    #Train the data on the one quater\n",
    "    model = model.fit(train_num_df_X,train_y)\n",
    "    model.score(train_num_df_X,train_y)  \n",
    "    \n",
    "    #Train the data on the one quater \n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X = scaler.fit_transform(train_num_df_X)\n",
    "    logistic_reg_acc_matrix=metrics.accuracy_score(train_y, stratified_cv(X, train_y, linear_model.LogisticRegression))\n",
    "    logistic_reg_class_matrix=metrics.classification_report(train_y, stratified_cv(X, train_y, linear_model.LogisticRegression))\n",
    "    logistic_reg_conf_matrix = metrics.confusion_matrix(train_y, stratified_cv(X, train_y, linear_model.LogisticRegression))\n",
    "    print('Logistic Regression accuracy on train data:           {:.2f}'.format(logistic_reg_acc_matrix))\n",
    "    print('Logistic Regression classification reprot on train data:\\n {}\\n'.format(logistic_reg_class_matrix))\n",
    "    dli_pred_test=model.predict(test_num_df_X)\n",
    "    logistic_reg_conf_matrix_test = confusion_matrix(test_y,dli_pred_test)\n",
    "    print('Creating confusion Matrix on Train and Test data')\n",
    "    conf_matrix = {                \n",
    "                    1: {\n",
    "                        'matrix': logistic_reg_conf_matrix,\n",
    "                        'title': 'Logistic Regression on Train Data',\n",
    "                       },\n",
    "                    2: {\n",
    "                        'matrix': logistic_reg_conf_matrix_test,\n",
    "                        'title': 'Logistic Regression on Test Data',\n",
    "                       },\n",
    "                 }    \n",
    "    confusion_matrix_data(conf_matrix)\n",
    "    expected = test_y\n",
    "    predicted = model.predict(test_num_df_X)\n",
    "    acc = np.sum(predicted == expected)/len(expected)\n",
    "    print(\"\")\n",
    "    print(\"Model Coeffiecient\")\n",
    "    print(model.coef_) \n",
    "    print(\"\")\n",
    "    print('accuracy on Test data={}'.format(acc))\n",
    "    acc = 0\n",
    "    print(\"\")\n",
    "    print(\"Classification report for Test data %s:\\n%s\\n\"\n",
    "     % (model, metrics.classification_report(expected, predicted)))     \n",
    "    fpr, tpr, _ = roc_curve(test_y,predicted)\n",
    "    #Plot ROC Curve\n",
    "    print('Creating ROC curve on Test data')\n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr,label=\"ROC Curve\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel(\"1-Specificity\")\n",
    "    plt.ylabel(\"Sensitivity\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calling Logistic Regression\n",
    "print(\"Calling Logistic Regression with train and test dataframes\")\n",
    "build_logistic_Regression(train_num_df_X, delinquent_train_y, test_num_df_X, delinquent_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_Random_Forest(train_num_df_X, train_y, test_num_df_X, test_y ):\n",
    "    model = RandomForestClassifier(n_estimators = 10)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X = scaler.fit_transform(train_num_df_X)\n",
    "    #Train the data on the one quater\n",
    "    random_acc_matrix=metrics.accuracy_score(train_y, stratified_cv(X, train_y, ensemble.RandomForestClassifier))\n",
    "    random_class_matrix=metrics.classification_report(train_y, stratified_cv(X, train_y, ensemble.RandomForestClassifier))\n",
    "    random_conf_matrix = metrics.confusion_matrix(train_y, stratified_cv(X, train_y, ensemble.RandomForestClassifier))\n",
    "    print('Random Forest accuracy on train data:           {:.2f}'.format(random_acc_matrix))\n",
    "    print('Random Forest classification reprot on train data:\\n {}\\n'.format(random_class_matrix))\n",
    "    model = model.fit(train_num_df_X,train_y)\n",
    "    model.score(train_num_df_X,train_y)\n",
    "    dli_pred_test=model.predict(test_num_df_X)\n",
    "    random_conf_matrix_test = confusion_matrix(test_y,dli_pred_test)\n",
    "    print('Creating confusion Matrix on Train and Test data')\n",
    "    conf_matrix = {                \n",
    "                    1: {\n",
    "                        'matrix': random_conf_matrix,\n",
    "                        'title': 'Ramdom Forest on Train Data',\n",
    "                       },\n",
    "                    2: {\n",
    "                        'matrix': random_conf_matrix_test,\n",
    "                        'title': 'Ramdom Forest on Test Data',\n",
    "                       },\n",
    "                 }    \n",
    "    confusion_matrix_data(conf_matrix)\n",
    "    expected = test_y\n",
    "    predicted = model.predict(test_num_df_X)\n",
    "    acc = np.sum(predicted == expected)/len(expected)\n",
    "    print(\"\")\n",
    "    print('accuracy on Test data={}'.format(acc))\n",
    "    acc = 0\n",
    "    print(\"\")\n",
    "    print(\"Classification report for Test data %s:\\n%s\\n\"\n",
    "     % (model, metrics.classification_report(expected, predicted)))\n",
    "    preds=model.predict_proba(test_num_df_X)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(test_y,preds)\n",
    "    \n",
    "    #Plot ROC Curve\n",
    "    print('Creating ROC curve on Test data')\n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr,label=\"ROC Curve\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel(\"1-Specificity\")\n",
    "    plt.ylabel(\"Sensitivity\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calling Random Forest Classification\n",
    "print(\"Calling Random Forest Classification with train and test dataframes\")\n",
    "build_Random_Forest(train_num_df_X, delinquent_train_y, test_num_df_X, delinquent_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_SVM(train_num_df_X, train_y, test_num_df_X, test_y ):\n",
    "    classifier = svm.LinearSVC(C=1)\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    X = scaler.fit_transform(train_num_df_X)\n",
    "    #Train the data on the one quater \n",
    "    svc_acc_matrix=metrics.accuracy_score(train_y, stratified_cv(X, train_y, svm.LinearSVC))\n",
    "    svc_class_matrix=metrics.classification_report(train_y, stratified_cv(X, train_y,svm.LinearSVC))\n",
    "    svc_conf_matrix = metrics.confusion_matrix(train_y, stratified_cv(X, train_y, svm.LinearSVC))\n",
    "    print('Support Vector accuracy on train data:           {:.2f}'.format(svc_acc_matrix))\n",
    "    print('Support Vector classification reprot on train data:\\n {}\\n'.format(svc_class_matrix))\n",
    "    model = classifier.fit(train_num_df_X,train_y)\n",
    "    classifier.score(train_num_df_X,train_y)\n",
    "    dli_pred_test=classifier.predict(test_num_df_X)\n",
    "    svm_conf_matrix_test = confusion_matrix(test_y,dli_pred_test)\n",
    "    print('Creating confusion Matrix on Train and Test data')\n",
    "    conf_matrix = {                \n",
    "                    1: {\n",
    "                        'matrix': svc_conf_matrix,\n",
    "                        'title': 'SVM on Train Data',\n",
    "                       },\n",
    "                    2: {\n",
    "                        'matrix': svm_conf_matrix_test,\n",
    "                        'title': 'SVM on Test Data',\n",
    "                       },\n",
    "                 }    \n",
    "    confusion_matrix_data(conf_matrix)\n",
    "    preds=classifier.predict(test_num_df_X)\n",
    "    \n",
    "    expected = test_y\n",
    "    predicted = classifier.predict(test_num_df_X)\n",
    "    acc = np.sum(predicted == expected)/len(expected)\n",
    "    print(\"\")\n",
    "    print('accuracy on Test data={}'.format(acc))\n",
    "    acc = 0\n",
    "    print(\"\")\n",
    "    print(\"Classification report for Test data %s:\\n%s\\n\"\n",
    "     % (classifier, metrics.classification_report(expected, predicted)))\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(test_y,preds)\n",
    "    #Plot ROC Curve\n",
    "    print('Creating ROC curve on Test data')\n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr,label=\"ROC Curve\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel(\"1-Specificity\")\n",
    "    plt.ylabel(\"Sensitivity\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calling Liner SVM Classification\n",
    "print(\"Calling Support Vector Machine with train and test dataframes\")\n",
    "build_SVM(train_num_df_X, delinquent_train_y, test_num_df_X, delinquent_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build a neural network\n",
    "def build_neural_network(train_num_df_X, train_y, test_num_df_X, test_y ):\n",
    " \n",
    "    #Calculating rows and columns for input dfs\n",
    "    trn_rows,trn_cols=train_num_df_X.shape\n",
    "    tst_rows,tst_cols=test_num_df_X.shape\n",
    "       \n",
    "    # build train dataset\n",
    "    print(\"Inside build_neural_network : \")\n",
    "    print(\"Building train dataset\")\n",
    "    train_data = ClassificationDataSet(trn_cols, 1 , nb_classes=2)\n",
    "    for k in range(len(train_num_df_X)): \n",
    "        train_data.addSample(train_num_df_X.iloc[k],train_y.iloc[k]) \n",
    "    \n",
    "    # build test dataset\n",
    "    print(\"Building test dataset\")\n",
    "    test_data = ClassificationDataSet(tst_cols, 1 , nb_classes=2)\n",
    "    for k in range(len(test_num_df_X)): \n",
    "        test_data.addSample(test_num_df_X.iloc[k],test_y.iloc[k])\n",
    "        \n",
    " \n",
    "    print(\"Train Dataset input length: {}\".format(len(train_data['input'])))\n",
    "    print(\"Train Dataset output length: {}\".format(len(train_data['target'])))\n",
    "    print(\"Train Dataset input|output dimensions are {}|{}\".format(train_data.indim, train_data.outdim))\n",
    "     \n",
    "    print(\"Train Data length: {}\".format(len(train_data)))\n",
    "    print(\"Test Data length: {}\".format(len(test_data)))\n",
    " \n",
    "    # encode with one output neuron per class\n",
    "    train_data._convertToOneOfMany()\n",
    "    test_data._convertToOneOfMany()\n",
    " \n",
    "    print(\"Train Data input|output dimensions are {}|{}\".format(train_data.indim, train_data.outdim))\n",
    "    print(\"Test Data input|output dimensions are {}|{}\".format(test_data.indim, test_data.outdim))\n",
    " \n",
    "    # build network (INPUT=10,HIDDEN=5,CLASSES=2,outclass=SoftmaxLayer)\n",
    "    print(\"Building Neural network with 5 hidden layer\")\n",
    "    network = buildNetwork(train_data.indim,5,train_data.outdim,outclass=SoftmaxLayer)\n",
    " \n",
    "    # train network\n",
    "    print(\"Training the network, it may take a while...\")\n",
    "    trainer = BackpropTrainer(network,dataset=train_data,momentum=0.1,verbose=True,weightdecay=0.01)\n",
    "    trainer.trainOnDataset(train_data, 1) #training model on One epoch\n",
    " \n",
    "    print(\"Total epochs: {}\".format(trainer.totalepochs))\n",
    " \n",
    "    # test network\n",
    "    print(\"Predicting the output array with the trained model\")\n",
    "    output = network.activateOnDataset(test_data).argmax(axis=1)\n",
    "     \n",
    "    #Neural network Percent error and accuracy    \n",
    "    print(\"Percent error: {}\".format(percentError(output, test_data['class'])))\n",
    "    accuracy=Validator.classificationPerformance(output, test_y)\n",
    "    print(\"Model Accuracy: {}\".format(accuracy))\n",
    "    print(\"Classification report for Test data %s:\\n%s\\n\"\n",
    "     % (network, metrics.classification_report(test_y, output)))\n",
    "    \n",
    "    \n",
    "    #Compute confusion metrics\n",
    "    cm_train = confusion_matrix(test_y,output)\n",
    "    cm_test = confusion_matrix(test_y,output)\n",
    "    conf_matrix = {                \n",
    "                    1: {\n",
    "                        'matrix': cm_train,\n",
    "                        'title': 'Neural Network on Train Data',\n",
    "                       },\n",
    "                    2: {\n",
    "                        'matrix': cm_test,\n",
    "                        'title': 'Neural Network on Test Data',\n",
    "                       },\n",
    "                 }    \n",
    "    confusion_matrix_data(conf_matrix) \n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(test_y,output)\n",
    "    #Plot ROC Curve\n",
    "    print('Creating ROC curve on Test data')\n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr,label=\"ROC Curve\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.05])\n",
    "    plt.xlabel(\"1-Specificity\")\n",
    "    plt.ylabel(\"Sensitivity\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calling Neural Network\n",
    "print(\"Calling neural network with train and test dataframes\")\n",
    "build_neural_network(train_num_df_X, delinquent_train_y, test_num_df_X, delinquent_test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def CopyToCSV(delinquent_test,cm,q1):\n",
    "    q1=\"2005\"\n",
    "    \n",
    "    columns=[\"Quarter\",\"Total Number of actual Deliquent\",\"Total Number of Predicted Deliquent\",\"Total Number of Records in Dataset\",\"Total Number of Deliquent Properly classified\",\"Total Number of Deliquent improperly classified\"]\n",
    "    df=pd.DataFrame();\n",
    "    rows=[q1,np.count_nonzero(delinquent_test==1),cm[1][0] + cm[1][1],len(test_num_df.axes[0]),cm[1][1],cm[1][0]]\n",
    "    df=df.append({q1,np.count_nonzero(delinquent_test==1),cm[1][0] + cm[1][1],len(test_num_df.axes[0]),cm[1][1],cm[1][0]},ignore_index = True)    \n",
    "    writeHeader = True\n",
    "    filename= \"DelinquentStatus.csv\"\n",
    "    if not os.path.exists(filename):\n",
    "        writeHeader = False\n",
    "    with open(filename, 'w',encoding='utf-8',newline=\"\") as f:\n",
    "        if writeHeader is False:\n",
    "            df.to_csv(f, mode='a', header=True,index=False)\n",
    "        else:\n",
    "            df.to_csv(f, mode='a', header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
